#!/usr/bin/env ruby
# Backs up a GitHub organization's repositories and
# all their associated information for archival purposes.
# Usage: ruby archive.rb

# stdlib
require 'yaml'
require 'logger'
require 'fileutils'
require 'open3'
require 'optparse'

# gems
require 'octokit'
require 'dotenv'

# variable to hold
parse_options = {}

optparse = OptionParser.new do |opts|
  opts.on('-o', '--org ORGANIZATION', "Organization Name") do |f|
    parse_options[:org] = f
  end
  opts.on("-v" "--version issues,wiki,repo", Array, "Version Issues, Wiki and/or Repo") do |list|
     parse_options[:version] = list
  end
end

optparse.parse!

# Configuration
Dotenv.load
Octokit.auto_paginate = true
token    = ENV["GITHUB_TOKEN"]
org      = parse_options[:org] || ENV["GITHUB_ORGANIZATION"]
dest_dir = ENV["GITHUB_ARCHIVE_DIR"] || File.expand_path("./archive/#{org}")

client   = Octokit::Client.new :access_token => token
logger   = Logger.new(STDOUT)
pwd      = Dir.pwd
start    = Time.now

# Timestamp each archive of the organization while still allowing custom archive directory in ENV
if parse_options.has_key?(:version) == true and parse_options[:version].include?("repo")
  dest_dir = "#{dest_dir}/#{start.strftime('%Y%m%dT%H%M%S')}"
end

# properties to extract from each issue for the archive
issue_keys = [:title, :number, :state, :html_url, :created_at, :closed_at]
milestone_keys = [:title, :number, :description, :state]
repo_info_keys = [:name, :full_name, :description, :private, :fork, :homepage, :forks_count, :stargazers_count, :watchers_count, :size]
team_keys = [:name, :slug, :description, :privacy, :permission]
team_member_keys = [:login, :site_admin, :type]
team_repo_keys = [:name, :full_name, :permissions]

# Run a git command, piping output to stdout
def git(*args)
  system "git " + args.join(" ")
end

# Init the archive dir
logger.info "Starting archive for #{org} in #{dest_dir}"
FileUtils.mkdir_p dest_dir unless Dir.exists? dest_dir

# Pull down Organization Teams and Team Members
org_teams = client.organization_teams org

# create folder for organizational team information
teams_dir = File.expand_path "teams", dest_dir
FileUtils.mkdir(teams_dir) unless Dir.exists? teams_dir

# Loop through each team
org_teams.each do |team|
  # Create path for each team file. Use the team slug name to ensure no filesystem issues.
  team_path = File.expand_path "#{team.slug}.md", teams_dir

  # Pull out relavent team info from team_keys
  team_info = {}
  team_keys.each { |key| team_info[key.to_s] = team[key] }

  # Begin to format team output
  team_output = "---\n\n"
  team_output << "# Team Info\n\n"
  team_output << team_info.to_yaml

  # Begin to format team repo output
  team_output << "---\n\n"
  team_output << "# Team Repos\n\n"

  # Pull down team repositories
  team_repos = client.team_repositories team.id
  team_repos.each do |repo|
    team_repo_info = {}
    team_repo_keys.each { |key| team_repo_info[key.to_s] = repo[key] }

    # Repo map permission hash from keys with symbols into strings
    team_repo_info["permissions"] = team_repo_info["permissions"].map {|k,v| {k.to_s => v}}

    # add team member info to team output
    team_output << team_repo_info.to_yaml
  end

  # Begin to format team member output
  team_output << "---\n\n"
  team_output << "# Team Members\n\n"

  # Pull down team members for current team
  team_members = client.team_members team.id

  # Pull out relavent team member info for each team member
  team_members.each do |member|
    team_member_info = {}
    team_member_keys.each { |key| team_member_info[key.to_s] = member[key] }

    # add team member info to team output
    team_output << team_member_info.to_yaml
  end

  # Write team info to disk
  File.write team_path, team_output
end

# Fetch all organization repositories
repos = client.organization_repositories org
logger.info "Found #{repos.count} repos"

# Loop through each repository
repos.each do |repo|
  repo_dir = File.expand_path repo.name, dest_dir
  clone_url = "https://#{token}:x-oauth-basic@github.com/#{org}/#{repo.name}.git"
  logger.info "  Archiving #{repo.name} to #{repo_dir}"

  # Git content
  if Dir.exists? repo_dir # Repo already exists, just pull new objects
    logger.info "    #{repo_dir} already exists. Pulling down updates"
    Dir.chdir repo_dir
    git "pull"
  else # Clone Git content from scratch
    logger.info "    #{repo_dir} does not exist. Cloning."
    git "clone", clone_url, repo_dir
  end

  # Clone wiki content
  if repo.has_wiki?
    wiki_clone_url = "https://#{token}:x-oauth-basic@github.com/#{org}/#{repo.name}.wiki.git"
    wiki_dir = File.expand_path "wiki", repo_dir

    if parse_options.has_key?(:version) == true and parse_options[:version].include?("wiki")
      wiki_dir = "#{wiki_dir}/#{start.strftime('%Y%m%dT%H%M%S')}"
    end

    logger.info "    Archiving #{repo.name}'s Wiki to #{wiki_dir}"
    `git clone #{wiki_clone_url} #{wiki_dir}`
  end

  # create folder for repo info
  repo_info_dir = File.expand_path "repo info", repo_dir
  FileUtils.mkdir(repo_info_dir) unless Dir.exists? repo_info_dir

  # Create path for repo info file.
  repo_info_path = File.expand_path "repo_info.md", repo_info_dir

  # Get relevant repo info
  repo_info = repo.to_h.select {|k,v| repo_info_keys.include?(k) }.map{ |k, v| {k.to_s => v}}

  # Begin to format repo info output
  repo_info_output = "---\n\n"
  repo_info_output << "# Repo Info\n\n"
  repo_info_output << repo_info.to_yaml

  # Write repo info to disk
  File.write repo_info_path, repo_info_output

  # Create an issues directory
  issues_dir = File.expand_path "issues", repo_dir

  if parse_options.has_key?(:version) == true and parse_options[:version].include?("issues")
    issues_dir = "#{issues_dir}/#{start.strftime('%Y%m%dT%H%M%S')}"
  end

  FileUtils.mkdir_p(issues_dir) unless Dir.exists? issues_dir

  # Pull down issues and pull requests
  issues = client.list_issues repo.full_name, :state => "all"
  logger.info "    Found #{issues.count} issues for #{repo.name}"

  # Loop through each issue or pull request
  issues.each do |issue|
    issue_path = File.expand_path "#{issue.number}.md", issues_dir
    logger.info "      Archiving issue ##{issue.number} to #{issue_path}"

    # Pull out issue meta (title, number, created date, etc.)
    meta = {}
    issue_keys.each { |key| meta[key.to_s] = issue[key] }
    meta["user"] = issue.user.login
    meta["tags"] = issue.labels.map {|l| l.name}
    meta["milestone"] = issue.milestone.to_h.select {|k,v| milestone_keys.include?(k) }.map{ |k, v| {k.to_s => v}}
    meta["assignee"] = issue.assignee.login

    # Begin to format our output
    output = meta.to_yaml
    output << "---\n\n"
    output << "# #{issue.title}\n\n"
    output << issue.body

    # Pull down and add comments
    if issue.comments > 0
      comments = client.issue_comments repo.full_name, issue.number
      logger.info "        Found #{comments.count} comments for issue ##{issue.number}"

      # Loop through each comment
      comments.each do |comment|
        output << "\n\n---\n"
        output << "@#{comment.user.login} at #{comment.created_at} wrote:\n\n"
        output << comment.body
      end
    end

    # Write issue + comments to disk
    File.write issue_path, output
  end
end

Dir.chdir pwd
logger.info "Done in #{Time.now - start} seconds."
